---
class name: Topic Models and Text Analysis
---
## Topic Modelling
Mallet (unsupervised learning algorithm) - probability

AC - buckets with most commonly used words within categories
decompose each document into its buckets 
	bucket 1 -4%... so on and so on...
	the following words are all associated with bucket 1.. 


*Mining the Dispatch*
*Topic Modelling Martha Ballard's Diary*


not about proving anything, but about changing your heuristic !! (seeing patterns)
	*how do you know how many topics to look for?*


TM: good practice before you run - write down what you think you're gonna find. 
	given what I know about this corpus of material, this is what I think will emerge 
		like proof before the critics hit you with the "we already knew this"
it's not always apparent off the bat what the topic is or how many subtopics there are

adding element of time to models can reveal more information


recap:
TM unsupervised way to pull words from texts - we have to tell the comuter how many buckets
historians use time because that's what we work with and can implement time into our graphs
we don't know necessarily what a topic means
	as historians we have to look at the words and figure out what the overarching topics are
visualizing the results
	raw numbers - ie. 85% talking about the weather
	small multiples - x year, y%, but SM remove axes and give smaller bites

*but can we so something different!?*
https://www.themacroscope.org/1.0/interactive-visualizations/


stemming
	going through premodelling getting rid of repeat word see: women and woman = wom


